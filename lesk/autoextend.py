# -*- coding: utf-8 -*-
"""autoextend.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RVoJG3JYCr0f8Yk1rmQDel_5QX0ICRHy
"""

import pandas as pd
from lesk.path import *
from tqdm import tqdm


class VecNet:
    def __init__(self, synsets):
        self.synsets = synsets


def load_lexemes(synset_offset, path=lexemes):
    """Loads lexemes from Autoextend Pre-train model and maps from wordnet version 1.7.1 to 3.0"""
    lexemes_df = pd.read_table(path)
    lexemes_df['word'] = lexemes_df['103055 300'].apply(lambda x: str(x).split('-')[0])
    lexemes_df['vec'] = lexemes_df['103055 300'].apply(lambda x: str(x).split(' ')[1:])  # .astype(float)
    lexemes_df['offset'] = lexemes_df['103055 300'].apply(lambda x: str(x).split(' ', 1)[0].split('-')[3]).astype(int)
    lexemes_df['pos'] = lexemes_df['103055 300'].apply(lambda x: str(x).split(' ', 1)[0].split('-')[4])
    uniq_words = synset_offset['word'].unique()
    merged_offset = lexemes_df.merge(synset_offset, on=['pos', 'offset'], how='inner')
    print(merged_offset.columns)
    return merged_offset[['word_y', 'vec', 'wn3', 'pos']], uniq_words


def vector_net(dataframe, unique):
    """Loads lexemes vector as VecNet instances"""
    vectornet_instances = {}
    for word in tqdm(unique):
        sample = dataframe[dataframe['word_y'] == word]
        synsets = sample[['vec', 'wn3', 'pos']].to_dict('list')
        vectornet_instances[word] = VecNet(synsets)
    return vectornet_instances
